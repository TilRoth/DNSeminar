\section{Related Work}
\label{sec:related}

In this section we highlight related work in the field. There are many papers regarding the GDPR on the impact or
the legal compliance of websites. We show the methodology and results of related papers and put the underlying
work~\cite{sanchez2019can} into context.

In 2018 \ca{degeling2018we} conducted a similar study to the one of \ca{sanchez2019can}. They evaluate the impact of the
GDPR on cookie consent notices and privacy policies. They only target websites inside the EU, and their domain are the
Alexa top-1M websites. The data collection for the cookie consent notices is manual meaning that
\citeauthor{degeling2018we} went through the websites of their domain by hand, and for privacy policies it is
semi-automated meaning that they tried to collect every privacy policy automated and if there was an error, they tried
it by hand. \citeauthor{degeling2018we} conclude that after the GDPR there are more readable privacy policies
and there are more cookie consent notices. However, they also say that these cookie notices may give users a false sense
of privacy and security since they often only inform the user that they are being tracked without the means to prevent
that. Users do not have more privacy online by only being informed that they are being tracked. The work of
\ca{sanchez2019can} follows a very similar methodology and reach a similar conclusion. They extend the work of
\ca{degeling2018we} by also taking international websites into account and observing the actual tracking that is being
performed after navigating through the cookie consent notice.

The \emph{whotracks.me} database released a blog post~\cite{whathappened} where they discuss the impact of the GDPR.
This database is based on real user data creating a realistic image of the situation. They compare USA-based websites to
websites inside the EU in terms of cookie tracking. The method for identification of tracking cookies is through known third-party
tracker lists. This method has the caveat of missing first-party tracking. Also, they do not factor in the consent of
users on tracking. The conclusion is that the average number of tracking cookies decreased in the EU and increased in
the USA. Cookie consent notices incorporate dark patterns manipulating users decisions on cookie control. The GDPR has
made the tracking market more concentrated meaning that smaller companies lose market share while bigger companies get
more powerful. To fix this problem, the post suggests having a machine-readable form of the GDPR such that the law can
not only be enacted through humans.

\ca{dabrowski2019measuring} measured cookies in the context of web privacy and the GDPR. Similar to other work in the
field they look at the impact of the GDPR on cookie tracking. One of their main goal is to evaluate whether clients from
different jurisdictions are treated differently on EU-based websites after the GDPR. Their target list is the Alexa
top-1M list, and they perform an automatic data collection by crawling the top 100,000 websites.
\citeauthor{dabrowski2019measuring} check for persistent (long-lasting) cookies set by websites, and they do not
additionally differentiate between tracking cookies and other cookies like \ca{sanchez2019can}. They conclude that EU
visitors are less likely to receive persistent cookies without consent. 49.3\% of websites of the top 1000 websites
according to Alexa do not set cookies without consent on EU visitors, when they would set them for visitors from the USA.

In 2020 \ca{nouwens2020dark} look into the design of cookie consent notices and detect dark patterns. A dark pattern is
a user interface that tricks users into desired behavior of the designers. They are not
concerned with the actual tracking but rather the legal aspect of the design of the consent notice. They consider a
consent notice to be compliant with the law (only a minimum requirement set by them, differs from case to case) if it
fulfills three aspects. First, consent must be explicit. Second, accepting all is as easy as rejecting all. Third, No
pre-ticked boxes. The target list is
the Alexa top-1M list, and they only choose sites from the UK. Their analysis is automatic via a web scraper.
\citeauthor{nouwens2020dark} conclude that many of the cookie consent notice designs are illegal according to the GDPR.
Only 11.8\% of websites they considered meet the minimum requirement they set to be acceptable regarding the GDPR.
Another result of their work is that placing any cookie controls below the first layer leads to people ignoring it. This
means that cookie consent notices where you have the \emph{Settings} option which lead you to a new layer of the notice
are ignored and just accepted because the users do not bother.

\ca{matte2020cookie} perform a similar study to \ca{nouwens2020dark}. They also check whether the cookie consent notice
complies with the GDPR. They choose the target list with Tranco, a tool for research which aggregates different rankings
of popular websites over a time period. The goal of Tranco is to overcome the disagreement of different lists and to accommodate
for changes of these lists over time. They perform an automatic analysis of their target list.
\citeauthor{matte2020cookie} do not consider the actual tracking but rather the compliance with the law
like \citeauthor{nouwens2020dark} do. 54\% of websites have at least one violation against the law where a violation is
one of the following: Consent stored before choice, no way to opt-out, pre-selected choices or non-respect of choice.
The results differ from \citeauthor{nouwens2020dark}(46\% legal~\cite{matte2020cookie} vs. 11.8\%
legal~\cite{nouwens2020dark}). This is probably due to stricter
requirements for websites to be legally compliant by \citeauthor{nouwens2020dark}.
They additionally provide a browser extension named \emph{Cookie Glasses} which can be used to detect the previously
mentioned violations on websites.

Another paper similar to \ca{sanchez2019can} is the one by \ca{trevisan20194} evaluating whether websites comply
with GDPR also in respect to tracking without consent. They provide a tool named \emph{CookieCheck} to perform this task
automated. The identification of third-party tracking cookies is done through known third-party tracker lists. Their
results of 49\% of websites tracking without consent differ from the ones of \citeauthor{sanchez2019can} which are about
90\% of websites tracking without consent. This can be due to the target list and the identification of trackers,
as \citeauthor{sanchez2019can} specified that their approach of identifying trackers is conservative. 49\% of
\citeauthor{trevisan20194} matches the result of \ca{matte2020cookie}, who conclude that about 54\% of cookie consent
banners violate the GDPR by e.g. storing consent when the user opts-out.

\ca{utz2019informed} performed a field study on the topic of cookie consent notices. They partnered with a german
e-commerce website with about 15,000 to 20,000 unique visitors per month in order to monitor the effects of different
cookie consent notices on users. This is an interesting setup since it is the first large-scale field study in this
research area getting data of actual users visiting a website. They deployed varying consent notices during their
study period and afterwards evaluated what effects the different designs had. \citeauthor{utz2019informed} highlight
that subtle differences in the design can have a substantial impact on user behavior (e.g. users tend to engage more
with cookie consent notices that are located at the bottom left of the screen). Their observations show that 0.1\% of
users accept the use of tracking cookies if there is a clear \emph{Accept} and \emph{Decline} option to opt-in (the
format required by the GDPR). This observation highlights why many websites do not implement this design of cookie
consent notices but rather implement dark patterns and nudging (deceiving users to accept cookies). The practice of dark
patterns and nudging has proven to work in getting more users to accept cookies. They conclude that the cookie consent
notice design specified by the GDPR is unrealistic because only 0.1\% of users would actually consent which is why many
websites implement dark patterns.

Related work on privacy policies evaluates the reading difficulty of privacy policies. \ca{jensen2004privacy} were among
the first to evaluate the reading difficulty using the FRES~\cite{flesch1948new} and FKRL~\cite{kincaid1975derivation} metrics.
Their target list of websites was the "comScore Media Metrix Top 50 U.S. Internet Property Ranking".
They looked at 64 different privacy policies of the target list and some sites from a previous study and got
an average FRES of about 34.2 and an average FKRL of about 14.2.
Based on these values \ca{sanchez2019can} concluded that privacy policies were more difficult to read in the past.
We go further into detail on the meaning of these values in \autoref{subsec:eval}. \citeauthor{jensen2004privacy}
conclude that privacy policies were too complicated for users to read or to make an informed decision upon.

\ca{mcdonald2009comparative} performed a comparative study of privacy policies. They evaluated the readability and the
acceptance of different formats of privacy policies as perceived by 749 participants in an online study. The conclusion
is that privacy policies are hard to read, and every format was equally disliked. The reading difficulty represented
through the FRES score did not make a difference in the understanding of privacy policies of the participants.
The assumption of \citeauthor{mcdonald2009comparative} is that a FRES of 32
to 46 (which was their range from hard to easy) does not have a substantial impact on the perception of the reader since even the easiest
privacy policies were too difficult for most people to understand. \citeauthor{sanchez2019can} got an average FRES of
54.1 on the privacy policies in their data set indicating that still to this day, privacy policies are too difficult
to read for the general population.

Other works conclude that privacy policies are lengthy and complicated resulting in users not reading them.
Privee~\cite{zimmeck2014privee} is a tool provided by
\citeauthor{zimmeck2014privee} which aims to extract the key features of privacy polices making them more
accessible for users. They offer the tool as a browser extension for Google Chrome. Privee is based on crowdsourcing and
automatic classification with the help of rule and machine learning. Overall they achieve a F1-score of 90\% (a
combination of precision and recall against their test set).
The limitation of this tool is the ambiguity of natural language which is also a problem for humans in legal documents thus
rendering the limitation as a problem of privacy policies in general and not only a problem of Privee.

